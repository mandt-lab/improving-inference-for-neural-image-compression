{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3c6f45-dfbb-447f-8d3b-1a2b2bb6dd54",
   "metadata": {},
   "source": [
    "# Encoding one image with SGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7d1de8-dd95-473b-ab0f-c45986d120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe39a4fe-a36e-4633-b27f-da37e4aee228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yiboyang/projects/improving-inference-for-neural-image-compression\n"
     ]
    }
   ],
   "source": [
    "cd ~/projects/improving-inference-for-neural-image-compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089f2712-4f78-4202-b283-5bf20144dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beae7ef2-a617-4240-aa67-13507f2ce725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 23:34:34.890664: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import numpy as np\n",
    "from absl import logging\n",
    "\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6099b5-a45c-4bd1-a6f6-8ecd8fa2614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587c806d-952b-4bca-98cc-73acd2c935f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([512, 768, 3]), tf.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_png(filename, channels=3):\n",
    "    \"\"\"Loads a PNG image file.\"\"\"\n",
    "    string = tf.io.read_file(filename)\n",
    "    return tf.image.decode_image(string, channels=channels)\n",
    "\n",
    "x = read_png(\"/home/yiboyang/data/kodak/kodim13.png\")\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da7cb7e-07dd-4548-8879-bb2330d37190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512, 768, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to float and add batch dim\n",
    "x = tf.cast(x, tf.float32)\n",
    "x = tf.expand_dims(x, 0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887ab17f-86f8-4b43-b56a-dc801b9c657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights from tf2_checkpoints/coco/mbt2018-num_filters=256-lmbda=0.08/ckpt-lmbda=0.08-epoch=400-loss=2.580\n"
     ]
    }
   ],
   "source": [
    "run_dir = 'tf2_checkpoints/coco/mbt2018-num_filters=256-lmbda=0.08/'\n",
    "from mbt2018 import MBT2018Model as Model\n",
    "import utils\n",
    "args = utils.get_args_as_obj(glob.glob(os.path.join(run_dir, 'args-*.json'))[0])\n",
    "model = Model.create_model(args)\n",
    "ckpt = tf.train.latest_checkpoint(run_dir)\n",
    "model.load_weights(ckpt)\n",
    "# model.compile()\n",
    "print('loaded weights from', ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7749a2-6902-4b7c-bb4c-aaf65f6b0642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.4320767, shape=(), dtype=float32) tf.Tensor(36.090073, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "res = model(x, training=False)\n",
    "print(res['bpp'], res['psnr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f18f32a-8059-4d3f-9785-6b93efd992c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n",
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, T=0.500 Train: loss=3.8182 mse=16.357 bpp=2.5097 psnr=35.9938\t Val: loss=3.7117 mse=15.996 bpp=2.4320 psnr=36.0907\n",
      "step=100, T=0.500 Train: loss=3.7438 mse=15.637 bpp=2.4928 psnr=36.1893\t Val: loss=3.6741 mse=15.548 bpp=2.4303 psnr=36.2140\n",
      "step=200, T=0.500 Train: loss=3.6766 mse=14.993 bpp=2.4772 psnr=36.3718\t Val: loss=3.6488 mse=15.231 bpp=2.4303 psnr=36.3035\n",
      "step=300, T=0.500 Train: loss=3.6243 mse=14.506 bpp=2.4638 psnr=36.5154\t Val: loss=3.6322 mse=15.020 bpp=2.4306 psnr=36.3642\n",
      "step=400, T=0.500 Train: loss=3.5899 mse=14.158 bpp=2.4573 psnr=36.6207\t Val: loss=3.6205 mse=14.868 bpp=2.4311 psnr=36.4083\n",
      "step=500, T=0.500 Train: loss=3.5620 mse=13.877 bpp=2.4518 psnr=36.7077\t Val: loss=3.6110 mse=14.736 bpp=2.4321 psnr=36.4471\n",
      "step=600, T=0.500 Train: loss=3.5415 mse=13.651 bpp=2.4494 psnr=36.7790\t Val: loss=3.6043 mse=14.645 bpp=2.4327 psnr=36.4738\n",
      "step=700, T=0.500 Train: loss=3.5242 mse=13.487 bpp=2.4452 psnr=36.8315\t Val: loss=3.5977 mse=14.552 bpp=2.4335 psnr=36.5016\n",
      "step=800, T=0.452 Train: loss=3.5205 mse=13.497 bpp=2.4408 psnr=36.8285\t Val: loss=3.5909 mse=14.458 bpp=2.4343 psnr=36.5297\n",
      "step=900, T=0.409 Train: loss=3.5237 mse=13.553 bpp=2.4395 psnr=36.8106\t Val: loss=3.5847 mse=14.370 bpp=2.4351 psnr=36.5562\n",
      "step=1000, T=0.370 Train: loss=3.5275 mse=13.623 bpp=2.4377 psnr=36.7882\t Val: loss=3.5792 mse=14.292 bpp=2.4359 psnr=36.5800\n",
      "step=1100, T=0.335 Train: loss=3.5274 mse=13.638 bpp=2.4364 psnr=36.7833\t Val: loss=3.5731 mse=14.204 bpp=2.4368 psnr=36.6067\n",
      "step=1200, T=0.303 Train: loss=3.5319 mse=13.701 bpp=2.4358 psnr=36.7634\t Val: loss=3.5669 mse=14.122 bpp=2.4371 psnr=36.6317\n",
      "step=1300, T=0.274 Train: loss=3.5337 mse=13.710 bpp=2.4369 psnr=36.7604\t Val: loss=3.5626 mse=14.062 bpp=2.4377 psnr=36.6504\n",
      "step=1400, T=0.248 Train: loss=3.5354 mse=13.741 bpp=2.4361 psnr=36.7506\t Val: loss=3.5580 mse=13.998 bpp=2.4382 psnr=36.6700\n",
      "step=1500, T=0.225 Train: loss=3.5389 mse=13.769 bpp=2.4374 psnr=36.7419\t Val: loss=3.5541 mse=13.942 bpp=2.4387 psnr=36.6875\n",
      "step=1600, T=0.203 Train: loss=3.5381 mse=13.761 bpp=2.4373 psnr=36.7444\t Val: loss=3.5505 mse=13.894 bpp=2.4390 psnr=36.7025\n",
      "step=1700, T=0.184 Train: loss=3.5386 mse=13.760 bpp=2.4378 psnr=36.7445\t Val: loss=3.5479 mse=13.856 bpp=2.4394 psnr=36.7143\n",
      "step=1800, T=0.166 Train: loss=3.5386 mse=13.752 bpp=2.4384 psnr=36.7472\t Val: loss=3.5458 mse=13.829 bpp=2.4395 psnr=36.7229\n",
      "step=1900, T=0.151 Train: loss=3.5396 mse=13.756 bpp=2.4391 psnr=36.7459\t Val: loss=3.5437 mse=13.797 bpp=2.4399 psnr=36.7329\n",
      "step=2000, T=0.136 Train: loss=3.5389 mse=13.746 bpp=2.4392 psnr=36.7489\t Val: loss=3.5416 mse=13.767 bpp=2.4402 psnr=36.7425\n",
      "step=2100, T=0.123 Train: loss=3.5394 mse=13.749 bpp=2.4395 psnr=36.7481\t Val: loss=3.5399 mse=13.743 bpp=2.4404 psnr=36.7499\n",
      "step=2200, T=0.112 Train: loss=3.5368 mse=13.720 bpp=2.4392 psnr=36.7572\t Val: loss=3.5388 mse=13.730 bpp=2.4404 psnr=36.7542\n",
      "step=2300, T=0.101 Train: loss=3.5369 mse=13.716 bpp=2.4396 psnr=36.7584\t Val: loss=3.5372 mse=13.713 bpp=2.4402 psnr=36.7594\n",
      "step=2400, T=0.091 Train: loss=3.5368 mse=13.710 bpp=2.4400 psnr=36.7605\t Val: loss=3.5365 mse=13.702 bpp=2.4404 psnr=36.7630\n",
      "step=2500, T=0.083 Train: loss=3.5357 mse=13.694 bpp=2.4401 psnr=36.7654\t Val: loss=3.5356 mse=13.686 bpp=2.4407 psnr=36.7681\n",
      "step=2600, T=0.075 Train: loss=3.5351 mse=13.685 bpp=2.4403 psnr=36.7682\t Val: loss=3.5353 mse=13.684 bpp=2.4406 psnr=36.7686\n",
      "step=2700, T=0.068 Train: loss=3.5349 mse=13.684 bpp=2.4402 psnr=36.7687\t Val: loss=3.5345 mse=13.669 bpp=2.4409 psnr=36.7734\n",
      "step=2800, T=0.061 Train: loss=3.5348 mse=13.674 bpp=2.4409 psnr=36.7719\t Val: loss=3.5345 mse=13.668 bpp=2.4411 psnr=36.7738\n",
      "step=2900, T=0.055 Train: loss=3.5347 mse=13.671 bpp=2.4410 psnr=36.7726\t Val: loss=3.5336 mse=13.658 bpp=2.4410 psnr=36.7770\n",
      "step=2999, T=0.050 Train: loss=3.5341 mse=13.658 bpp=2.4414 psnr=36.7769\t Val: loss=3.5337 mse=13.656 bpp=2.4412 psnr=36.7774\n",
      "CPU times: user 5min 19s, sys: 21.3 s, total: 5min 40s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sga import default_sga_schedule\n",
    "num_steps = 3000\n",
    "(y, z), val_res = model.iterative_infer(x, num_steps, default_sga_schedule, learning_rate=1e-3, log_every_steps=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
